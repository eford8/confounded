\documentclass[11pt]{article}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage{authblk}
\usepackage{url}
\usepackage[inline,shortlabels]{enumitem}
\usepackage[square,numbers]{natbib}
\usepackage{floatrow}
\floatsetup[table]{capposition=top}
\usepackage[nomarkers,nolists]{endfloat}
\usepackage[margin=1in,letterpaper]{geometry}
\usepackage{multirow}
\usepackage[table]{xcolor}
\usepackage[hidelinks]{hyperref}
\usepackage{lineno}
\linenumbers

\bibliographystyle{unsrtnat}

\begin{document}

\title{Adversarial Deep Neural Networks Effectively Remove Nonlinear Batch Effects from Gene-Expression Data}
\author{Jonathan Bryan Dayton}
\author[1]{Jonathan B. Dayton}
\author[1]{Stephen R. Piccolo}
\affil[1]{Department of Biology, Brigham Young University, Provo, UT 84602 USA}

\maketitle

\begin{abstract}
	Gene-expression profiling enables researchers to quantify transcription levels in cells, thus providing insight into functional mechanisms of diseases and other biological processes.
	However, because of the high dimensionality of these data and the sensitivity of measuring equipment, expression data often contains unwanted confounding effects that can skew analysis.
	For example, collecting data in multiple runs causes nontrivial differences in the data (known as batch effects),
	known covariates that are not of interest to the study may have strong effects,
	and there may be large systemic effects when integrating multiple expression datasets.
	Additionally, many of these confounding effects represent higher-order interactions that may not be removable using existing techniques that identify linear patterns.
	We created Confounded to remove these effects from expression data.
	Confounded is an adversarial variational autoencoder that removes confounding effects while minimizing the amount of change to the input data.
	We tested the model on artificially constructed data and commonly used gene expression datasets and compared against other common batch adjustment algorithms.
	We also applied the model to remove cancer-type-specific signal from a pan-cancer expression dataset.
	Our software is publicly available at \url{https://github.com/jdayton3/Confounded}.
\end{abstract}

\doublespacing
\section{Background} \label{sec:background}

Gene expression data can be applied in many ways to advance our understanding of medicine and biology.
For example, expression data has been applied to discover conserved genetic modules \citep{stuart_gene-coexpression_2003}, to better understand the mechanisms of cardiovascular disease \citep{henriksen_application_2002}, to more accurately predict the clinical outcome in cancer patients \citep{veer_gene_2002}, and to discover effective drugs for treating specific diseases \citep{sirota_discovery_2011}.
Expression datasets are quite ``wide,'' often containing tens of thousands of columns representing each gene in the human transcriptome.
Because of the sensitive nature of these data (i.e. gene product levels in organisms may respond drastically to small environmental changes) and of the equipment used to quantify expression levels, expression data often contains unwanted confounding effects that can skew analysis.
Three examples of this include
\begin{enumerate*}[(a)]
	\item batch effects, \label{it:batch}
	\item known covariates, and \label{it:cov}
	\item dataset-level effects. \label{it:int}
\end{enumerate*}
\ref{it:batch} Batch effects occur when expression data are generated in multiple runs or multiple batches, and slight systemic differences occur during the different runs, such as different technicians operating the machine or slight temperature differences in the room.
Batch effects are understood to have a nontrivial impact on high-throughput expression data \citep{leek_tackling_2010}.
In one study, researchers found that, contrary to previous knowledge, expression values from mice and humans clustered more closely by species than by tissue type \citep{yue_comparative_2014};
however, referees showed in a rebuttal that when accounting for batch effects, these data actually clustered more closely by tissue type, as initially expected \citep{gilad_reanalysis_2015}.
\ref{it:cov} Systemic bias can be even more pronounced when there are known covariates---for example, using data collected from different cancer types when cancer type is not of interest to the study \citep{dayton_classifying_2017-1}.
\ref{it:int} Finally, though batch effects within a dataset collected all by one lab at one time may be somewhat decreased experimentally by careful replication of experimental conditions, this is no longer possible when integrating different datasets;
however, much better statistical significance can be achieved when analyzing larger datasets, so data integration is a key goal for transcriptomic analysis  \citep{lazar_batch_2013}.
Each of these problems---batch effects, known covariates, and dataset integration---represents a case where data measurements are effected by some hidden variables and must be removed for effective analysis (see \figurename{} \ref{fig:workflow}).


\begin{figure}
	\centering
	\includegraphics[width=\columnwidth]{figures/final/adjuster_workflow.pdf}
	\caption[Batch adjustment justification and steps]{\textbf{Batch adjustment justification and steps.}
	\begin{enumerate*}[(a)]
		\item When measurements are collected from a sample ($X$), systemic effects ($H$) may affect the measurements.
		\item If data from the same sample $X$ is measured under two different conditions, $H_1$ and $H_2$, we may obtain slightly different measurements.
		\item In order to normalize batches of data relative to one another, we first estimate the effect of the hidden variables based on differences in measurements between batches.
		\item Second, we remove the estimated effects in order to normalize the batches relative to one another.
	\end{enumerate*}
	}
	\label{fig:workflow}
\end{figure}

Several methods exist for characterizing and removing batch effects from gene-expression data.
Two commonly used methods are ComBat \citep{johnson_adjusting_2007} and SVA \citep{leek_capturing_2007}.
ComBat uses an empirical Bayes approach to estimate batch effect parameters and then uses linear regression to model and remove the effects. SVA uses singular value decomposition to model batch effects, which can then be accounted for in statistical analyses.
Both of these methods use linear methods to model confounding effects and thus may not account for nonlinear effects, such as multi-gene, cascading interactions within signaling pathways.
As machine learning becomes more common in biological research, these nonlinear confounding effects become more troublesome because many machine-learning algorithms can successfully account for complex interactions among variables.
%For example, advances in neural networks have introduced new ways to account for higher-order, nonlinear relationships in data.
%These networks have proven effective in removing irrelevant, domain-specific signal in credit-rating, online-review, and image-recognition tasks \citep{louizos_variational_2015}.

Artificial neural networks, a category of machine-learning algorithms, are inspired by the way human brains function; input values pass through layers of linear and nonlinear functions, the final output values are measured against specific objectives, and the function layers are adjusted to bring the outputs closer to the objectives; this process is repeated until the outputs are sufficiently close to their targets \citep{schmidhuber_deep_2015}.
Neural networks have been applied broadly to gene-expression data. For example, they have been used to detect cancer and identify critical cancer genes \citep{danaee_deep_2016}, to impute gene-expression levels from the values of a few ``landmark genes'' \citep{chen_gene_2016}, to extract biologically relevant latent spaces in RNA-Seq data \citep{way_extracting_2017}, to reduce the dimensions of single-cell RNA-Seq data \citep{lin_using_2017}, to identify drug-repurposing targets \citep{aliper_deep_2016}, and to generate synthetic biomedical data as a way to preserve patient privacy \citep{beaulieu-jones_privacy-preserving_2017}.

Recent progress has been made in using artificial neural networks to correct batch effects in expression data \cite{shaham_removal_2017,shaham_batch_2018,upadhyay_removal_2019}.
However, these methods are designed for a limited range of scenarios:
1) when the input data contain only two batches, 
2) the batches are sufficiently large (> 100 samples in our testing), and 
3) the batches are balanced.[@For #2, does this mean the total number of samples? Or the number of samples per batch? Please clarify the wording.@] 
These requirements rarely hold in applied research; for example, the bladderbatch dataset---which is used to test batch-adjustment techniques\cite{leek_bladderbatch_2017,leek_sva_2017}---has 5 batches, 57 samples, and 4 to 19 samples per batch.
Additionally, existing methods for batch correction have not been tested to verify whether nonlinear patterns remain in expression data after batch correction.
To address these limitations, we implemented a deep neural network that [@describe our method briefly, what is different about our method, and why we think our method can be applied when there are >2 batches, small datasets, and unbalanced batches.@] 
Furthermore, we tested our method using machine-learning classification algorithms to quantify the extent to which nonlinear batch effects remained after adjustment.

Autoencoders are a type of neural network that encodes input data in fewer dimensions and then reconstructs the data in the original dimensions\citep{hinton_reducing_2006}[@Please verify that this is a correct reference to use here.@].
This technique can be used to reduce noise and thus refine the data representation.[@Make sure this wording is legit.@]
Typically, autoencoders are trained using an objective function that seeks to ensure that the output is as similar as possible to the input \citep{hinton_reducing_2006}. 
However, neural networks are adept at finding subtle patterns in data; thus the objective function may prioritize replication of confounding patterns, such as batch effects, rather than the signals of interest \citep{ganin_domain-adversarial_2015,louizos_causal_2017-2}.[@Make sure this wording and the references are appropriate.@] 
Recently, researchers have experimented with discouraging neural networks from learning such patterns by giving them two competing objective functions: 1) to maximize similarity between in the input and output data and 2) to ignore any patterns associated with known confounding variables \citep{ganin_domain-adversarial_2015,tzeng_deep_2014-2}.
Louizos, et al. have used this type of dual-objective function in combination with a variational autoencoder and successfully removed domain-based variability in credit scores, financial savings, and hospital admittance datasets \citet{louizos_variational_2015}.

In this study, we present \textit{Confounded}, an adversarial autoencoder that identifies and removes confounding effects from gene-expression data.
We test the hypothesis that using an adversarial neural network can correct for confounding effects more effectively than alternative tools.
We present a classification-based framework to assess the extent to which confounding effects remain after adjustment, and we apply these techniques to four datasets.

\section{Methods} \label{sec:methods}

All our code has been made publicly available at \url{https://github.com/jdayton3/Confounded}, and all our data are available as described below.

\subsection{Network Structure}

We used an adversarial autoencoder network to model and remove the confounding effects.
We structured this network in two parts: a variational autoencoder \cite{louizos_variational_2015} to replicate the input (expression) data and a discriminator to detect remaining confounding effects in the autoencoder's output.
By penalizing the autoencoder for the discriminator's success, the autoencoder subnetwork learned over the course of training to output the expression data with confounding effects minimized.
We implemented the neural network in TensorFlow 1.11.0 \cite{abadi_tensorflow_2015} with Python 3.6 \cite{python_software_foundation_python_2019}.
All layers in the network were fully connected and all activation functions were Rectified Linear Units (ReLUs) \cite{agarap_deep_2018} except the final layers in the autoencoder and the discriminator, which used the sigmoid function.

\begin{figure}
	\centering
	\includegraphics[width=\columnwidth]{figures/final/network.pdf}
	\caption[Network architecture of Confounded]{\textbf{Network architecture of Confounded.}
	Data with batch effects (represented by different colors) are input into an autoencoder.
	The output of the autoencoder is classified by a discriminator network based on batch.
	The autoencoder is then penalized based on the success of the discriminator.
	Over time, the autoencoder learns to output a faithful representation of the data without signal due to batch.}
	\label{fig:network}
\end{figure}

\subsubsection{Autoencoder}

We implemented the variational autoencoder \citep{louizos_variational_2015} described by \citet[Chapter 15]{geron_hands-machine_2017}.
This network has 2 hidden encoding layers and 2 decoding layers, each of size 500.
The code size is 20.
Each hidden layer is activated with the Exponential Linear Unit (ELU) function \citep{clevert_fast_2015}.
It is trained with the Adam optimizer \citep{kingma_adam_2014} on reconstruction loss (sigmoid cross entropy) combined with latent loss (KL divergence \citep{kullback_information_1951}).

\subsubsection{Discriminator}

We trained the discriminator to determine the original batch of the autoencoder's output.
The discriminator subnetwork consists of an input layer; four fully connected hidden layers of sizes 1024, 512, 512, and 128, respectively; and an output layer sized based on the number of batches.
In order to combat overfitting and improve training, we also added 50\%-probability dropout \cite{srivastava_dropout_2014} (which prevents overfitting by dropping a random subset of layer inputs in each training iteration) and batch normalization \cite{ioffe_batch_2015} (which helps training by smoothing out the optimization landscape \citep{santurkar_how_2018}) to each layer of the discriminator.
These additions seemed to reduce overfitting in the discriminator.

\subsubsection{Loss functions}

We trained the network using three loss functions.
First, we calculated the autoencoder's loss ($L_A$) by summing the reconstruction loss (sigmoid cross entropy between the autoencoder's input and output) and the latent loss (Kullback-Leibler (KL) divergence \cite{kullback_information_1951} of the code layer).
Second, we calculated the discriminator's loss ($L_D$) as sigmoid cross entropy between its output and a one-hot encoding of the samples' batch labels.
Finally, we also trained the autoencoder layers on a combination of the two previous losses,

\begin{equation}
	\label{dual_loss}
	L_{dual} = L_A - \lambda{}(L_D)
\end{equation}

The $\lambda$ value represents a tradeoff parameter for tuning the network's tendency for more faithfully replicating the input or for more completely removing confounding effects.
A higher $\lambda$ value indicates that the network should remove confounding effects more aggressively, whereas a lower value indicates that the network should instead favor faithfully reconstructing the input data.
We did not optimize $L_A$ directly; instead we trained the autoencoder by optimizing $L_{dual}$.

\subsubsection{Training}

In all cases, we trained the network using the Adam Optimizer \citep{kingma_adam_2014} with a training rate of 0.0001 for 10,000 iterations on mini-batches of size 100.
In each iteration, we optimized on both $L_D$ and $L_{dual}$.
When optimizing $L_D$ (i.e. training the discriminator), we froze the autoencoder's weights, and vice versa.
We trained the network on a 2017 Dell XPS 15 9560 with an 8-core Intel i7-7700HQ CPU and 16 GB of RAM.
For each dataset, training typically took roughly 30 minutes to complete, including the time taken to load the input into memory and to save the output to disk.

\begin{figure}
	\centering
	\includegraphics[width=\columnwidth]{figures/final/training_loss.pdf}
	\caption[Autoencoder and discriminator loss]{\textbf{Autoencoder and discriminator loss} over time for one run of Confounded on the MNIST dataset.
	Over the course of training, the autoencoder more faithfully replicates the input data.
	The autoencoder also seems to introduce noise (see the red dashed line around iteration 3100) in response to the discriminator's slight improvements.}
	\label{fig:training_loss}
\end{figure}

\subsection{Datasets}

In order to test both theoretical and practical differences between Confounded and previous methods, we compared them for a variety of datasets of varying sizes and type of data measured.

\begin{table}
	\centering
	\input{figures/final/datasets.tex}
	\caption[Dataset information]{
		\textbf{Dataset information} for each dataset used.
	}
	\label{tab:datasets}
\end{table}

\subsubsection{MNIST}

The MNIST digits dataset \cite{lecun_mnist_nodate} is a database of images of handwritten digits that are size-normalized and centered.
It contains 60,000 training images and 10,000 test images.
We used MNIST so we could visually assess how well the true signal (in this case, the shape and digit of each handwritten digit image) was preserved after batch adjustment.
In order to use this dataset, we flattened each 28 by 28 image into a 1D vector of size 784 and put each in a CSV file along with the accompanying digit information.
We limited our dataset to only the 10,000 test images.
Although convolutional layers are typically used when working with image data, we only used fully connected layers even for this image dataset.
In this way, we show that the autoencoder is still able to find and represent spatial relationships without explicitly defining spatial relationships in the model while testing the same network we use on expression data, where no spatial relationships are inherent.

\paragraph{Synthetic Batch Effects}

Because there is no batch information in the MNIST digits dataset, we had to simulate nonlinear confonding effects.
To do so, we wrote a Python script to take the MNIST data in, apply a nonlinear effect, and output the adjusted data.
We applied nonlinear effects by iteratively realizing vectors of normally distributed values, multiplying and adding these vectors to the ``expression'' vectors, and applying nonlinearity to the adjusted vector.
We split the image data into two batches while keeping the batches balanced (5,000 images for each batch) and including the same number of each digit in each batch.
We applied the same random vectors to each image in a batch.
Finally, we added random noise to each image in order to prevent images in a batch from being overly similar to each other.

\subsubsection{Bladderbatch}

The bladderbatch dataset is a microarray transcriptomic expression dataset from a study of patients with bladder cancer \cite{dyrskjot_gene_2004}.
It has been made available as an R package \cite{leek_bladderbatch_2017} and is used in the documentation of the sva R package \cite{leek_sva_2017} to illustrate how to batch-adjust using ComBat.
It contains expression values for 57 tissue samples with and without bladder cancer across 5 unbalanced batches.
The dataset has a cancer status (cancerous vs. normal tissue) column, which we used for ``true class'' classification, and a batch column.
Because bladderbatch is such a small dataset in terms of typical deep learning datasets, we selected it as a way to test whether our network was overfitting.

\subsubsection{GSE37199}

The GSE37199 dataset contains Affymetrix microarray gene-expression data from patients with advanced castration-resistant prostate cancer \cite{olmos_prognostic_2012}.
We accessed a version of this dataset from \url{http://doi.org/10.17605/OSF.IO/SSK3T} that was tidied as part of a curated compendium of human transcriptional biomarker data \cite{golightly_curated_2018}.
It contains expression values for 93 tissue samples categorized as either ``Advanced castration resistant'' or ``good prognosis.''
We used this cancer status variable as the ``true class'' for classification.
It has two types of batch variables: ``plate'' and ``centre.''
We adjusted against the ``plate'' variable because it was more balanced than ``centre'' (with counts of $\{43, 50\}$ compared to $\{27, 66\}$).
The GSE37199 dataset represents a slightly larger dataset than bladderbatch, with only two batches that are closer to being balanced (with batch counts of $\{4, 5, 11, 18, 19\}$ and $\{43, 50\}$, respectively).

\subsubsection{TCGA Pan-cancer Data}

The Cancer Genome Atlas (TCGA) Pan-Cancer project produced expression data for thousands of tumors across many cancer types \cite{the_cancer_genome_atlas_research_network_cancer_2013}.
In a previous study \cite{dayton_classifying_2017-1}, we classified this dataset based on the presence or absence of mutations in several known cancer genes.
We attempted to adjust for the confounding effect of cancer type using ComBat prior to classification.
However, we found that a strong nonlinear signal could still be identified by the Random Forests algorithm after adjustment.
Here, we used the same version of the dataset that we tidied in this previous study (available at \url{https://osf.io/7xjdn/}).
This dataset has RNA-Seq expression values for 9,365 samples across 25 distinct cancer types.
We used this dataset as a way to test whether Confounded works on RNA-Seq data and to test whether we could remove confounding effects that ComBat cannot remove.

\subsection{Comparison to other methods}

We compared our method to two other batch adjusters: a scale adjuster and ComBat \citep{johnson_adjusting_2007}.
We implemented the scale adjuster in the R programming language, version 3.6.0 \citep{r_core_team_r_2014} using RStudio version 1.2.1194 \citep{rstudio_team_rstudio_2018}.
It adjusts the data by linearly expanding or contracting each batch so all batches have the same range.
We used the ComBat implementation from the R sva package \citep{leek_sva_2017} with some modifications to allow it to work on columns without variance in the MNIST dataset.
We initially intended to test against the SVA \citep{leek_capturing_2007} method but concluded that SVA is more suited for producing surrogate variables for further statistical research rather than removing those variables from the data.
There are a number of other methods for batch adjustment that do and do not use deep neural networks (for example, see \citep{leek_capturing_2007,espin-perez_comparison_2018,shaham_removal_2017,shaham_batch_2018}).
Unfortunately, most of these methods lack a common interface and common assumptions that input datasets must meet.
For these reasons, we compared Confounded only to the two methods listed above.
Future batch adjustment research may benefit from standardization of input formats, user interfaces, and validation datasets.

\subsection{Statistics and Metrics}

\subsubsection{Mean squared error}

Mean squared error (MSE) is a measure of how much two vectors or matrices deviate from one another.
It is commonly used as a loss value in autoencoders to make the network minimize the difference between the input and output values.
We wanted to see how well Confounded and other batch correction software maintain patterns in the input data as measured by MSE.

\subsubsection{Maximum mean discrepancy} \label{section:mmd}

In a recent paper, \citet{shaham_removal_2017} used neural networks to remove batch effects.
Instead of constraining the autoencoder to remove batch effects based on a discriminator, these researchers trained their network to minimize maximum mean discrepancy (MMD) between batches in an embedded layer of their network.
We calculated MMD using the same formula as \citeauthor{shaham_removal_2017} to determine whether batches looked like they came from the same distribution after adjustment.
For the kernel, we used the Gaussian kernel between two batches as implemented in \texttt{sklearn.metrics.pairwise.rbf\_kernel} \cite{pedregosa_scikit-learn_2011}.
In cases where there were more than two batches, we averaged all pairwise MMD values to calculate an overall MMD.

\subsubsection{Classification accuracy}

In order to determine \begin{enumerate*}[(a)]
	\item whether batch can still be identified post-adjustment and
	\item how well class-related signal is maintained after adjustment,
\end{enumerate*}
we determined classification accuracy based on batch and ``true class'' labels using several machine learning classifiers.

We used four classifiers from the scikit-learn 0.19.1 Python library \cite{pedregosa_scikit-learn_2011} in order to classify on batch and true class before and after adjustment: Naive Bayes \citep{maron_automatic_1961}, Random Forests \citep{tin_kam_ho_random_1995}, k-Nearest Neighbors \citep{fix_discriminatory_1951}, and SVM \citep{cortes_support-vector_1995} with a radial basis kernel.
Table \ref{tab:datasets} details which columns were used for training.

We calculated the average of classification accuracies for four-fold cross-validation repeated three times.
We interpret lower accuracy for batch classification as meaning that the batch is removed more effectively.
We also interpret higher true class classification as meaning that the important signal is not lost during the process of adjustment.
Therefore, given output data from the ideal batch adjuster, batch classification would be no better than random for any classification algorithm, and true class accuracy would be no lower than accuracy for the unadjusted data.

\section{Results} \label{sec:results}

In this study, we created Confounded, an adversarial variational autoencoder neural network, to remove nonlinear batch and confounding effects from expression data that may not be accounted for by traditional linear methods.
We compared Confounded to a scaling method and to ComBat \citep{johnson_adjusting_2007} using various metrics.
The scaling method performed consistently worse across the qualitative and quantitative evaluations that we performed;
ComBat and Confounded performed relatively well overall, but each of these algorithms excelled in different types of scenarios, which we illustrate below.

\subsection{Confounded removes nonlinear confounding effects that other adjusters miss}

To compare Confounded to other batch adjustment methods, we compared PCA and t-SNE plots along with MSE, MMD, and classifier batch prediction accuracy (using various classifiers).

PCA and t-SNE plots seem to show a decrease in separability after adjustment with various methods for the GSE37199 dataset (see \figurename{s} \ref{fig:pca} and \ref{fig:tsne}).
However, previous research has shown that these plots are not completely trustworthy in representing nonlinear effects \cite{dayton_classifying_2017-1}.
In the PCA plot, Confounded appears to maintain a similar distribution to the unadjusted data, indicating that the underlying distribution has been faithfully reproduced by the networks.
The t-SNE plot shows that the data post-adjustment by Confounded and ComBat appear to cluster less tightly by batch than the unadjusted and scale-adjusted data.
This may indicate an effective removal of nonlinear effects in both cases.

\begin{figure}
	\centering
	\includegraphics[width=\columnwidth]{figures/final/pca.pdf}
	\caption[Principal components analysis (PCA)]{\textbf{Principal components analysis} (PCA) of the GSE37199 dataset before and after batch adjustment with various adjusters.
	None of the datasets appear to be linearly separable.
	Confounded appears to maintain the same distribution of data overall as the unadjusted data while perhaps aligning the batches' distributions.}
	\label{fig:pca}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[width=\columnwidth]{figures/final/tsne.pdf}
	\caption[T-distributed Stochastic Neighbor Embedding (t-SNE)]{\textbf{T-distributed Stochastic Neighbor Embedding (t-SNE)} plot for the GSE37199 dataset before and after adjustment with several algorithms.
	The data seem to cluster less by batch for both Confounded and ComBat, indicating that both adjusters may be removing nonlinear effects in this dataset.}
	\label{fig:tsne}
\end{figure}

Confounded shows mixed success with the MSE and MMD metrics.
With MSE, Confounded outperformed the scale adjuster in 3 of the 4 datasets but scored drastically worse on the MNIST dataset, with scores listed in Table \ref{tab:mse} (see also \figurename{} \ref{fig:mse}).
With MMD, Confounded outperformed the scale adjuster again in 3 of the 4 datasets and tied the scale adjuster on the TCGA dataset, with scores listed in Table \ref{tab:mmd} (see also \figurename{} \ref{fig:mmd}).
With both metrics, Confounded consistently performed somewhat worse than ComBat.

\begin{figure}
	\centering
	\includegraphics[width=\columnwidth]{figures/final/mse.pdf}
	\caption[Mean squared error (MSE)]{
		\textbf{Mean squared error} (MSE) between the data prior to and after adjustment with various algorithms.
		Lower MSE represents that the adjuster has more faithfully reproduced the input data.
		MSE for unadjusted data will always be 0 because the input data is identical to the output data.
		Confounded usually performs better than the scale adjuster and somewhat worse than ComBat when measuring MSE.
		See also Table \ref{tab:mse}.
	}
	\label{fig:mse}
\end{figure}
\begin{table}
	\input{figures/final/mse.tex}
	\caption[Mean squared error (MSE)]{
		\textbf{Mean squared error (MSE)} of the unadjusted input data compared to the data output by the given adjusters.
		Lower MSE indicates that the output has changed less from the input.
		See also \figurename{} \ref{fig:mse}.
	}
	\label{tab:mse}
\end{table}
\begin{figure}
	\centering
	\includegraphics[width=\columnwidth]{figures/final/mmd.pdf}
	\caption[Maximum mean discrepancy (MMD)]{
		\textbf{Maximum mean discrepancy} (MMD) between different batches.
		Lower MMD indicates that the distributions of the different batches are more similar.
		In cases with more than two batches, MMD is computed pairwise between each batch and averaged.
		In each case, Confounded usually performs better than the scale adjuster and somewhat worse than ComBat when measuring MSE.
		See also Table \ref{tab:mmd}.
	}
	\label{fig:mmd}
\end{figure}
\begin{table}
	\centering
	\input{figures/final/mmd.tex}
	\caption[Maximum mean discrepancy (MMD)]{
		\textbf{Maximum mean discrepancy} (MMD) comparing the distributions of the batches to each other after a given adjustment.
		Lower MMD indicates that the distributions of the different batches are more similar.
		In cases with more than two batches, MMD is computed pairwise between each batch and averaged.
		See also \figurename{} \ref{fig:mmd}.
	}
	\label{tab:mmd}
\end{table}

We would expect that after batch adjustment by an ideal adjuster, batch would no longer be detectable by any machine learning classifier.
Using the batch classification accuracy metric, Confounded seems to outperform other adjusters on larger datasets, whereas ComBat and Confounded seem to perform about the same on smaller datasets (see \figurename{} \ref{fig:batch}).
With both the bladderbatch and GSE37199 datasets, batch classification accuracy decreases well below baseline after batch adjustment with ComBat for all classifiers we tested (see Table \ref{tab:batch}).
Interestingly, batch accuracy also decreases drastically for the MNIST and TCGA datasets, but only for the Naive Bayes classifier.
This may be due to two factors: both ComBat and Naive Bayes use Bayesian methods, so ComBat may specifically remove the effects that Naive Bayes identifies; and Naive Bayes does not find patterns based on interactions between variables.
Although Naive Bayes is no longer able to identify confounding effects in the data after ComBat-adjustment, Random Forests (which does use interactions between variables) still has a very high accuracy for MNIST and an increased accuracy for TCGA.
In contrast, after adjustment by Confounded, the Random Forests algorithm's accuracy decreases more than with any other adjuster for both the MNIST and TCGA datasets.
This indicates that while ComBat's performance may work at least as well as Confounded for smaller expression datasets, Confounded may work better with larger datasets.

\begin{figure}
	\centering
	\includegraphics[width=\columnwidth]{figures/final/batch_accuracy.pdf}
	\caption[Batch classification accuracy]{\textbf{Batch classification accuracy} from 4-fold cross-validation repeated 3 times for several classifiers.
	Lower batch accuracy indicates that more batch-related signal has been removed and therefore indicates better performance.
	Confounded's performance is similar to ComBat's for the smaller datasets and is improved for the larger datasets.
	See also Table \ref{tab:batch}.}
	\label{fig:batch}
\end{figure}
\begin{table}
	\centering
	\input{figures/final/batch.tex}
	\caption[Batch classification accuracy]{
		\textbf{Batch classification accuracy} for several datasets and adjusters.
		The ideal batch adjuster would completely remove all signal due to batch and would therefore \textit{decrease} batch classification accuracy to around the baseline for all classifiers.
		See also \figurename{} \ref{fig:batch}.
	}
	\label{tab:batch}
\end{table}

With the larger datasets in particular, Confounded outperforms the other adjusters.
On the MNIST dataset, Random Forests is able to detect batch with perfect or near-perfect accuracy after adjustment with the scale adjuster and ComBat, but the highest batch classification accuracy after adjustment by Confounded is Naive Bayes, with an accuracy of 68.8\%.
With TCGA, both the scale adjuster and ComBat drastically increase Random Forests' batch classification accuracy from 87.6\% to 96.3\% and 97.1\% respectively, whereas Confounded decreases the accuracy to 8.8\%.

\subsection{Class-related signal is still detectable after adjustment by Confounded}

With the smaller datasets, Confounded seems to keep true class information roughly as well as ComBat, (with Random Forests, Bladderbatch: 74.3 for ComBat\% and 72.1\% for Confounded, GSE37199: 60.4\% for ComBat and 69.0\% for Confounded; see \figurename{} \ref{fig:true_class} and Table \ref{tab:true_class}).
For the Bladderbatch dataset, true class accuracy is much lower after adjusting with any algorithm, indicating that cancer status and batch may not be independent.

With the larger datasets, Confounded's true class accuracy consistently decreases below the accuracy of other adjusters.
A look at the MNIST digits before and after adjustment (see \figurename{} \ref{fig:mnist}) shows that Confounded's output is often blurry, as is common with the output of variational autoencoders \cite{hou_deep_2016}.
With MNIST, Confounded's accuracy with Random Forests is still much higher than baseline (84.8\% vs. 11.4\%), but with TCGA, the accuracy decreases below baseline (66.5\% vs. 69.8\%) while the other adjusters' accuracies remain above baseline.
However, the particular set of parameters that we used in Confounded are likely not optimal for every dataset.
Additional tuning may improve the performance metrics.

\begin{figure}
	\centering
	\includegraphics[width=\columnwidth]{figures/final/true_class_accuracy.pdf}
	\caption[True class classification accuracy]{\textbf{True class classification accuracy} for several datasets and adjusters with 4-fold cross-validation repeated 3 times. A higher accuracy after adjustment is desired because it represents that the adjuster has not destroyed the true class signal.
	See also Table \ref{tab:true_class}.}
	\label{fig:true_class}
\end{figure}
\begin{table}
	\centering
	\input{figures/final/true_class.tex}
	\caption[True class classification accuracy]{
		\textbf{True class classification accuracy} for several datasets and adjusters.
		After adjustment by the ideal batch adjuster, all true class signal should be preserved, and all classifiers should therefore have the same accuracy in predicting true class before and after adjustment.
		See also \figurename{} \ref{fig:true_class}.
	}
	\label{tab:true_class}
\end{table}

\begin{figure}
	\centering
	\includegraphics[width=\columnwidth]{figures/final/mnist.png}
	\caption[MNIST handwritten digits]{\textbf{MNIST handwritten digits}
	\begin{enumerate*}[(a)]
		\item before any adjustment,
		\item with artificial noise added,
		\item adjusted for noise by the scale adjuster,
		\item adjusted for noise by ComBat, and
		\item adjusted for noise by Confounded.
	\end{enumerate*}
	Although Confounded seems to remove more noise from the background, it struggles in some cases to accurately replicate the input data.}
	\label{fig:mnist}
\end{figure}

\section{Discussion} \label{sec:discussion}

\textbf{Why should I use a neural network for batch adjustment?}
The process of measuring data typically leaves confounding effects, especially when the data or measurement process involves living things.
Imagine an experiment where two researchers measure the length of caterpillars.
If one researcher is left-eye dominant and the other is right-eye dominant, they may each see lengths as being a millimeter different.
If both researchers use the same wooden ruler at different relative humidities, the measurements may come out differently due to the wood swelling or due to the caterpillars reactions to humidity.
These same types of problems exist when measuring expression levels, but to more of an extreme---in addition to the target values and measuring equipment changing slightly due to systemic factors, the target values also change in response to each other.
Each of the 20,000 transcript levels may influence or be influenced by other transcript levels.
These cascading network-like effects are extremely likely to have nonlinear components, and our research shows that these nonlinear effects do indeed exist in gene expression data, thus rendering linear batch correction methods insufficient.
Therefore, some form of nonlinear adjustment must be used in order to correct for real-world confounding effects.
Rather than individually model each of infinitely many possible nonlinear interactions to see which represent confounders, we can use a neural network to both approximate and remove the confounders, since neural networks are proven to be universal function approximators \citep{csaji_approximation_2001}.

\textbf{How can I tell how well batch adjustment worked?}
Although the metrics and figures that have been used in the past to validate batch adjustment (such as PCA, MSE, and MMD) represent how well linear effects have been removed, they cannot completely display whether two batches are distinguishable from one another.
Machine learning algorithms are designed specifically to tease out patterns in data that may distinguish one group from another.
We suggest to users of batch correction software that they use machine learning classification accuracy before and after correction in order to determine the degree of batch removal.
We also suggest to researchers in the field of batch correction that classification accuracy be used as a metric in validating their software.
Specifically, the Random Forests algorithm \citep{tin_kam_ho_random_1995} seems to work very well and runs relatively quickly on gene expression data.

\textbf{Which batch adjuster should I use?}
In our testing, ComBat did very well with small ($n < 100$) datasets, even with removing any identifiable nonlinear effects.
However, Confounded outperformed ComBat on the larger datasets according to the batch classification accuracy metric.
In addition to dataset size, researchers selecting a batch adjustment algorithm should consider how important it is for them to accurately replicate their input data.
Such researchers can adjust Confounded's $\lambda$ parameter in order to balance the tradeoff of removing batch and matching the inputs.

\textbf{What limitations does Confounded have?}
\begin{enumerate*}[(a)]
	\item Confounded uses a variational autoencoder, which are known for often outputting a blurry version of the input data (as can be seen in \figurename{} \ref{fig:mnist}).
	However, recent work has identified modifications that may be made to the basic VAE structure to make output images sharper and more realistic \citep{hou_deep_2016}.
	Similar research with variational autoencoders and gene expression data may yield improved reconstruction losses and decrease the blurring effect.
	\item Confounded takes a long time to run in comparison with ComBat and other linear adjusters.
	Although we acknowledge this as a downfall of many types of machine learning and of neural network in particular, we believe that 30-60 minutes is a reasonable amount of time for a step that will be run only once per pipeline and that can greatly improve data quality.
	\item It can be difficult to identify the optimal network structure and parameter set for a neural network.
	Though this is the case for many applications of neural networks, we feel that Confounded's default structure worked well in our testing and that it will suffice for most batch correction applications.
	\item Neural networks usually perform better when given large amounts of data, and traditional batch datasets typically have very few samples.
	We did find that ComBat may outperform Confounded on many smaller, more traditional datasets, but that Confounded performs better on larger datasets.
	However, Confounded did perform reasonably well with the smaller datasets and appeared to avoid overfitting.
	In cases where ComBat is unable to completely remove confounding effects in a small dataset, Confounded may be a viable replacement method.
\end{enumerate*}

\textbf{What else might Confounded be used for?}
At its root, batch correction is a data integration problem:
data from multiple batches must have batch-specific confounding effects removed in order to be treated as one dataset.
Confounded shows promise in removing traditional batch effects from microarray expression data in the Bladderbatch and GSE37199 datasets.
It also effectively decreased artificial batch effects in image data and cancer-type-specific confounding effects in RNA-Seq data.
Confounded may be effective in other data integration problems, such as combining microarray with RNA-Seq datasets, or merging several large datasets measured under different conditions.

Confounded, and adversarial autoencoders in general, show promise as a valuable way to remove confounding biases from expression datasets.
Such methods will enable researchers access to larger datasets, therefore increasing the scope of analyses and furthering science as a whole.

\newpage
\phantomsection
\addcontentsline{toc}{section}{References}
\bibliography{references}

\end{document}
